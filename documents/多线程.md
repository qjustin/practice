#多线程
>1.那么请谈谈 AQS 框架是怎么回事儿？
* AQS 维护着一个双向链表队列，当线程获取同步状态失败后，加入到队列的尾部并一直保持自旋，自旋时会判断前驱节点是否是首节点，如果是则不断尝试获取同步状态，获取成功则从同步队列中退出，执行完毕后释放同步状态，唤醒后续节点。

>2.请尽可能详尽地对比下 Synchronized 和 ReentrantLock 的异同。
* ReentrantLock是API级别的，synchronized是JVM级别的
* ReentrantLock可以实现公平锁
* ReentrantLock通过 Condition可以绑定多个条件
* synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生； 而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象， 因此使用Lock时需要在finally块中释放锁。
* Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时， 等待的线程会一直等待下去，不能够响应中断。
* 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到

>3.什么是可重入锁？
* 获得锁的线程可以重复进入锁
	
>4.实现可重入需要解决那些问题？
* 当前线程的判断
* 锁释放
	
>5.ReentrantLock如何实现可重入性的？
* 在AQS中维护了一个 volatile state来计数重入次数，避免了频繁的持有释放操作带来效率问题。
* 当一个线程在获取锁过程中，先判断state的值是否为0，如果是表示没有线程持有锁，就可以尝试获取锁
* 当state的值不为0时，表示锁已经被一个线程占用了，获取当前持有锁的线程，看看这线是不是自己，是则进入state+1

>6.synchronized如何实现可重入性？
* synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令。
* 每个锁对象内部维护一个计数器，该计数器初始值为0，表示任何线程都可以获取该锁并执行相应的方法。
* 根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，
* 或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，
* 当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。

>7.请谈谈 ReadWriteLock 和 StampedLock。
* StampedLock 不可重入，使用需要使用一个long型邮戳，用于加锁解锁，必须使用finally+unlock(stamp)
* ReadWriteLock 可重入，一个线程写多个线程并发度，度时不能写，写时不能度。

>8.如何让 Java 的线程彼此同步？
* Synchronized ，ReentrantLock 来进行同步

>9.你了解过哪些同步器，请分别介绍下？
* CountDownLatch 
    * 必须发生指定数量的事件后才可以继续运行(比如赛跑比赛，裁判喊出3,2,1之后大家才同时跑)
    * CountDownLatch(int count):必须发生count个数量才可以打开锁存器
    * await:等待锁存器
    * countDown:触发事件
* CyclicBarrier
    * 适用于只有多个线程都到达预定点时才可以继续执行(比如斗地主，需要等齐三个人才开始)
    * CyclicBarrier(int num) :等待线程的数量
    * CyclicBarrier(int num, Runnable action) :等待线程的数量以及所有线程到达后的操作
    * await() : 到达临界点后暂停线程
    * reset() : 重置
* Semaphore
    * 经典的信号量，通过计数器控制对共享资源的访问
    * Semaphore(int count):创建拥有count个许可证的信号量
    * acquire()/acquire(int num) : 获取1/num个许可证
    * release/release(int num) : 释放1/num个许可证
* Exchanger<T> 用于线程间进行数据交换
    * 没用过
* Phaser同步器
    * 工作方式与CyclicBarrier类似，但是可以定义多个阶段
    * Phaser()/Phaser(int num) : 使用指定0/num个party创建Phaser
    * register() : 注册party
    * arriveAndAdvance() : 到达时等待到所有party到达
    * arriveAndDeregister() : 到达时注销线程自己
	
>10.CyclicBarrier 和 CountDownLatch 看起来很相似，请对比下呢？
* CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用，

>11.JVM 对 Java 的原生锁做了哪些优化？
* 自旋锁
    * 自旋等待虽然避免了线程切换的开销，但自旋的线程要占用处理器时间的，所以若锁被占用的时间很短，自旋等待的效果就会非常好，反之锁被占用的时间很长，那么自旋的线程只会白白消耗 CPU 资源。
    * 因此自旋等待的时间必须要有一定的限度，超过限定的次数仍然没有成功获得锁，就应当挂起（阻塞）线程了。自旋次数的默认值是 10 次。
* 锁消除
    * 在动态编译同步块的时候，JIT 编译器可以借助一种被称为逃逸分析（Escape Analysis）的技术来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。从而取消对这部分代码的同步。
* 锁粗化
    * 当 JIT 编译器发现一系列连续的操作都对同一个对象反复加锁和解锁，甚至加锁操作出现在循环体中的时候，会将加锁同步的范围扩散（粗化）到整个操作序列的外部。
* 自适应自旋锁
    * 在 JDK 1.6 中引入了自适应自旋锁。
    * 自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。
    * 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。
    * 如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。

>12.为什么说 Synchronized 是非公平锁？
* 非公平是一种获取锁的行为，主要是为了减少线程切换，提高性能，但可可能会产生线程饥饿现象

>13.为什么说 Synchronized 是一个悲观锁？乐观锁的实现原理又是什么？
* 不管是否需存在线程竞争，都对资源进行加锁。同步块内只有一个线程能进入
* 乐观锁基于CAS实现，不锁资源，不会导致线程阻塞。可以任务是Synchronize的优化。
    * 它涉及到三个操作数：内存值、预期值、新值。当且仅当预期值和内存值相等时才将内存值修改为新值。
    * 如果：不一样则表示期间此内存值已经被别的线程更改过，就舍弃本次操作

>14.CAS与synchronized的使用情景？
* 对于资源竞争较少（线程冲突较轻）的情况使用CAS，因为使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；
		而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
* 对于资源竞争严重（线程冲突严重）的情况Synchronized：因为CAS自旋的概率会比较大， 从而浪费更多的CPU资源，效率低于synchronized。

>15.乐观锁一定就是好的吗？乐观锁的缺点（ABA问题）
* ABA问题如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。
* 自旋时间长开销大
    * 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 
* 只能保证一个共享变量的原子操作 CAS只对单个共享变量有效，当操作涉及跨多个共享变量时CAS无效。 

>16.JVM 如何解决ABA问题
* 解决ABA最简单的方案就是给值加一个修改版本号，每次值变化，都会修改它版本号，CAS操作时都对比此版本号。
* AtomicStampedReference主要维护包含一个对象引用以及一个可以自动更新的整数"stamp"的pair对象来解决ABA问题。

>17.Java 中的线程池是如何实现的？
* executor:提交任务
* 饱和策略
* 阻塞不队列
* hashSet线程引用集合

>18.创建线程池的几个核心构造参数？
* corePoolSize ：核心线程数，到达核心线程数后，新任务进入队列
* maxPoolSize：核心线程数满，且任务队列已满时，线程池会创建新的线程，直到线程数量达到maxPoolSize。
* keepAliveTime：当线程空闲时间达到keepAliveTime，该线程会退出，直到线程数量等于corePoolSize。如果allowCoreThreadTimeout设置为true，则所有线程均会退出直到线程数量为0。
* allowCoreThreadTimeout：是否允许核心线程空闲退出，默认值为false。
* workQueue：一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。
* queueCapacity：任务队列的容量会影响到线程的变化，因此任务队列的长度也需要恰当的设置。
* 饱和策略
    * AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 
    * DiscardPolicy：也是丢弃任务，但是不抛出异常。 
    * DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
    * CallerRunsPolicy：由调用线程处理该任务 

>19.读写锁的锁降级，为什么要降级？
* 锁降级：当前线程持有写锁的同时，获取读锁，获取读锁成功，再释放写锁。
* 原因：线程A持有写锁说明A对数据进行过修改，如果线程A先释放写锁，线程B立即获取了写锁，并更新数据，这中间没有给其他线程机会去读取线A程写入的值  

>20.公平锁于非公平锁的区别
* 公平锁保证获取锁的顺序按照先进先出原则，不会连续获得锁，线程切换增多性能下降，但不会产生饥饿
* 非公平锁，释放锁的线程立即加入锁竞争，可能连续获得锁，线程切换减少，吞吐量加，但可能会产生饥饿
	
>21.什么是 Java 的内存模型，
* JVM内存模型的作用在于屏蔽操作系统以及硬件的差异，达到访问内存效果的一致性。
* JVM内存模型定义了并发过程中如何处理原子性，可见性，有序性
    * 原子性：内存模型来直接保证原子性的变量操作包括read、load、use、assign、store、write这6个动作
				并发情况下工作内存 写入 缓存 ，缓存写入工作内存的原子性。
    * 可见性：volatile，synchronized和final，保证变量对所有线程的可见性
    * 有序性：volatile和synchronized，volatile禁止了指令重排序，而synchronized则由“一个变量在同一时刻只能被一个线程对其进行lock操作”来保证

>22.Java 中各个线程是怎么彼此看到对方的变量的？
* volatile 来保证可见性，volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取，

>23.请谈谈 volatile 有什么特点，为什么它能保证变量对所有线程的可见性？
* volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取，
* 解决一个线程对变量的修改，对另一个线程不可见
* CPU缓存一致性协议实现

>24.请对比下 volatile 对比 Synchronized 的异同。
* volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住；
* volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的；
* volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性；
* volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞；
* volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。

>25.什么是ThreadLocal？
* 线程同步机制是多个线程共享同一个变量，而ThreadLocal是为每个线程创建一个单独的变量副本，
* 每个线程都可以改变自己的变量副本而不影响其它线程所对应的副本。
* 定义：线程本地变量。
* 作用域：线程内部。
* 生命周期：伴随线程执行始终，线程结束，变量生命结束。
* 共享性：多个线程之间不共享。

>26.ThreadLocal内部实现？
* ThreadLocal有一个静态内部类ThreadLocalMap，Entry继承自WeakReference，key为当前的ThreadLocal对象，value为对应线程的变量副本
* get()、set()、remove()都是基于该内部类进行操作
* 所以对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。

>27.请谈谈 ThreadLocal 是怎么解决并发安全的？
* 线程安全问题产生的两个前提条件：
    * 数据共享。多个线程访问同样的数据。
    * 共享数据是可变的。多个线程对访问的共享数据作出了修改。
* ThreadLocal和解决线程安全没有关系, ThreadLocal变量的副本，不予任何线程共享

>28.很多人都说要慎用 ThreadLocal，谈谈你的理解，使用 ThreadLocal 需要注意些什么？
* ThreadLocal使用不当会引起内存泄漏，内部的ThreadLocalMap，key是弱引用，所以key'会在垃圾回收的时候被回收掉， 而key对应的value则不会被回收， 这样会导致一种现象：key为null，value有值。
* 解决办法是，每次使用完ThreadLocal都调用它的remove()方法清除数据。

>29.ThreadLocal弱引用导致内存泄漏，那为什么key不设置为强引用
* 如果key设置为强引用， 当threadLocal实例释放后， threadLocal=null， 但是threadLocal会有强引用指向threadLocalMap，threadLocalMap.Entry又强引用threadLocal， 这样会导致threadLocal不能正常被GC回收。Key 弱引用 ThreadLocal 强引用 ThreadLocalMap 强引用 Key

>30.为什么ThreadLocal要被声明成静态的？不声明成静态的行不行？
* 可以是非静态的，最好是static的，避免创建多无意义的ThreadLocal示例。
* 当static时，ThreadLocal ref生命延长－ThreadMap的key在线程生命期内,始终有值－ThreadMap的value在线程生命期内不释放
	 
>31.线程池中的线程是怎么创建的？
* ExecutorService fixedPool1 = Executors.newFixedThreadPool(10);
		
>32.编写一个死锁程序？
* 程序在main()方法中启动2个线程，“线程-A”和“线程-B”。 
* 线程-A 先拿到 lockA，再寻求拿到 lockB
* 线程-B 先拿到 lockB，再需求拿到 lockA
* 造成死锁。
	
>33.Synchronized 用过吗，其原理是什么？
* Synchronized 系统提供的非公平可重入同步锁，锁的释放由系统完成。
* 并且monitor调用的是操作系统底层的互斥量(mutex),本身也有用户态和内核态的切换。

>34.锁的升级过程？
* 无锁 -> 偏向锁  -> 轻量锁  -> 重量级锁
* 无锁 -> 偏向锁升级过程
* 当有线程第一次进入同步块时，锁状态为00（无锁），线程将在对象头和当前线程的线程栈上记录下threadID，下次进入同步块只需比较当前线程的threadID是否与对象头中的threadID相等，无须使用cas进行加锁解锁，
* 如果threadID相等
    * 锁仍然为无锁状态，当前线程获得锁成功，无须cas竞争锁
* 如果threadID不相等
    * 查看对象头中记录的线程是否存活
        * 如果死的
            * 将锁状态重置为无锁状态，当前线程将锁设置为偏向自己
        * 如果活的
            * 看看线程是否还继续持有这个锁对象
                * 是：暂停当前线程，升级为轻量锁
                * 否：将锁状态重置为无锁状态，当前线程将锁设置为偏向自己
* 轻量锁 -> 重量锁升级过程
    * 线程1获取轻量级锁，先把对象MarkWork拷贝到线程栈中displacemarkwrod，使用cas操作将displacemarkwrod地址存入对象头中，
    如果这个CAS失败，说明别的线程（线程2）也在做同样的操作，并且线程2先一步更新了markwork，线程1自旋等待线程2释放锁。
    如果线程1 自旋次数到达或者有线程3来竞争锁.则升级为重量级锁，并阻塞所有等待的线程，防止浪费CPU。